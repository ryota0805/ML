{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA RTX A2000 8GB Laptop GPU\n",
      "2.0.0+cu118 True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "print(torch.cuda.get_device_name())\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pd.read_csv('../data/env1/x_extract.csv', delimiter=',',encoding=\"utf-8-sig\", header=None).values.tolist()\n",
    "y_data = pd.read_csv('../data/env1/y_extract.csv', delimiter=',',encoding=\"utf-8-sig\", header=None).values.tolist()\n",
    "theta_data = pd.read_csv('../data/env1/theta_extract.csv', delimiter=',',encoding=\"utf-8-sig\", header=None).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make input data and ouptput data\n",
    "input_data_1 = []\n",
    "input_data_2 = []\n",
    "output_data = []\n",
    "\n",
    "for i in range(np.shape(x_data)[0]):\n",
    "    input_data_2_list = [x_data[i][0], x_data[i][-1], y_data[i][0], y_data[i][-1], theta_data[i][0], theta_data[i][-1]]\n",
    "    for j in range(1, np.shape(x_data)[1]):\n",
    "        x = x_data[i][0:j]\n",
    "        y = y_data[i][0:j]\n",
    "        input_data_1_list = []\n",
    "        for k in range(len(x)):\n",
    "            input_data_1_list.append([x[k], y[k]])\n",
    "        input_data_1.append(input_data_1_list)\n",
    "        input_data_2.append(input_data_2_list)\n",
    "        output_data.append([x_data[i][j], y_data[i][j]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.764922937, 2.257040621],\n",
       " [-0.784877232, 2.552430241],\n",
       " [0.352215063, 2.895154319]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.764922937, 29.18854837, 2.257040621, 0.716586999, 0.292744299, 0.839522787]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, input_data_1, input_data_2, output_data):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.input_data_1 = input_data_1\n",
    "        self.input_data_2 = input_data_2\n",
    "        self.output_data = output_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_1 = torch.tensor(self.input_data_1[index], dtype=torch.float32)\n",
    "        input_2 = torch.tensor(self.input_data_2[index], dtype=torch.float32)\n",
    "        output = torch.tensor(self.output_data[index], dtype=torch.float32)\n",
    "        return input_1, input_2, output\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_data = MyDataset(input_data_1, input_data_2, output_data)\n",
    "\n",
    "val_size = 2000\n",
    "train_data, val_data = torch.utils.data.random_split(train_valid_data, [len(train_valid_data)-val_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0859,  0.3388],\n",
       "         [ 0.0859,  0.3388],\n",
       "         [ 0.6437, -1.5818],\n",
       "         [ 2.2623, -2.5050],\n",
       "         [ 3.7339, -2.2085],\n",
       "         [ 4.7066, -1.5221],\n",
       "         [ 5.5161, -0.7597],\n",
       "         [ 6.2683,  0.0424],\n",
       "         [ 7.0621,  0.9023],\n",
       "         [ 8.1799,  1.9895]]),\n",
       " tensor([ 0.0859, 28.0988,  0.3388,  2.1004, -1.2882, -1.1793]),\n",
       " tensor([9.0733, 2.5118]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_valid = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, output_seq_length, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_seq_length = output_seq_length\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=self.num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #入力のsequence長さを出力のsequence長さに合わせるため拡張する\n",
    "        new_size = (x.size(0), self.output_seq_length, input_size)\n",
    "        x = x.expand(*new_size)\n",
    "        \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        output, _ = self.lstm(x, (h0, c0))\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, output_seq_length, num_layers):\n",
    "        super(LSTM_MLP, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_seq_length = output_seq_length\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=self.num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        #入力のsequence長さを出力のsequence長さに合わせるため拡張する\n",
    "        new_size = (x.size(0), self.output_seq_length, input_size)\n",
    "        x = x.expand(*new_size)\n",
    "        \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        output, _ = self.lstm(x, (h0, c0))\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded Sequences:\n",
      " tensor([[1, 2, 3, 0],\n",
      "        [4, 5, 0, 0],\n",
      "        [6, 7, 8, 9]])\n",
      "Padding Mask:\n",
      " tensor([[1., 1., 1., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1.]])\n",
      "Packed Sequences:\n",
      " PackedSequence(data=tensor([6, 1, 4, 7, 2, 5, 8, 3, 9]), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=tensor([2, 0, 1]), unsorted_indices=tensor([1, 2, 0]))\n",
      "Batched Sequences:\n",
      " tensor([3, 3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "\n",
    "# 入力シーケンスのリストを作成\n",
    "sequences = [torch.tensor([1, 2, 3]), torch.tensor([4, 5]), torch.tensor([6, 7, 8, 9])]\n",
    "\n",
    "# パディング\n",
    "padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "\n",
    "# パディングのマスキング\n",
    "padding_mask = (padded_sequences != 0).float()\n",
    "\n",
    "# パック・パディング・シーケンス\n",
    "packed_sequences = pack_padded_sequence(padded_sequences, lengths=[3, 2, 4], batch_first=True, enforce_sorted=False)\n",
    "\n",
    "# バッチ化\n",
    "batched_sequences = packed_sequences.batch_sizes\n",
    "\n",
    "# 出力を確認\n",
    "print(\"Padded Sequences:\\n\", padded_sequences)\n",
    "print(\"Padding Mask:\\n\", padding_mask)\n",
    "print(\"Packed Sequences:\\n\", packed_sequences)\n",
    "print(\"Batched Sequences:\\n\", batched_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
